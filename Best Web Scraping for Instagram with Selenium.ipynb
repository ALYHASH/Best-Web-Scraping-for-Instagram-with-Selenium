{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Best Web Scraping for Instagram with Selenium**\n","metadata":{}},{"cell_type":"markdown","source":"# **IMPORTANT**\n# **DOWNLOAD THIS NOTEBOOK AND RUN IT IN \"JUPYTER NOTEBOOK\"**\n\n- ## **Chrome Driver NOT RUN ON KAGGLE**\n","metadata":{}},{"cell_type":"markdown","source":"![](https://res.cloudinary.com/ddqdqrrgt/image/upload/v1725943214/X.png)","metadata":{}},{"cell_type":"markdown","source":"# Install selenium Libraries\n\n- Selenium libraries allows you to interact with dynamic content and scroll through the page to load more posts.\n- there is a lot of more other options that can help you too \n      \n ### **First web scraping techniques :**\n     -BeautifulSoup\n     -Selenium\n                                                             \n ### **Second third-party libraries like :**\n     -Instaloader                                    ","metadata":{}},{"cell_type":"code","source":"pip install selenium","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade selenium # IF NEADED","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **\" DON'T \"**  \n\n# **RUN** **THE**  **CELLS**\n\n# **RUN**  **THE**  **WHOLE**  **CODE**\n\n# **AT THE END OF NOTEBOOK**","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport time\nimport urllib.request\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.keys import Keys","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Download Chrome Driver**\n\nimportant\n\n**Now we need to download latest stable release of ChromeDriver from:**\n\nhttps://github.com/GoogleChromeLabs/chrome-for-testing/blob/main/data/latest-versions-per-milestone-with-downloads.json","metadata":{}},{"cell_type":"code","source":"# Set the path to your ChromeDriver (In Kaggle, you'll need to install ChromeDriver first)\ndriver_path = r'E:\\driver\\chromedriver-win64\\chromedriver.exe'  # Replace with the correct path for Kaggle or download it in the notebook\n\n# Set up Chrome options (Headless mode is useful when running in Kaggle, as there is no GUI)\nchrome_options = Options()\n\n# Initialize WebDriver\nservice = Service(executable_path=driver_path)\ndriver = webdriver.Chrome(service=service, options=chrome_options)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **login to the page by writing  \"username\" & \"password\"**","metadata":{}},{"cell_type":"code","source":"# Instagram login page\ndriver.get('https://www.instagram.com/accounts/login/')\ntime.sleep(2)  # Wait for the login page to load\n\n# Find the username and password fields and enter credentials\n# *** You need to replace the username and password  ***\nusername_field = driver.find_element(By.NAME, 'username')\npassword_field = driver.find_element(By.NAME, 'password')\nusername_field.send_keys('4ooha2')  # Replace with your credentials\npassword_field.send_keys('alyhassan')  # Replace with your credentials\npassword_field.send_keys(Keys.RETURN)  # Press Enter to log in\n\ntime.sleep(5)  # Wait for login to complete","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **trick number 1**\n\n- now you have to targit your goal and \"classes\" \n- and ('https://www.instagram.com/explore/tags/{hashtag}/') is our goal and classes are hashtags\n- browser is -40 zoom out to see more images in the browser","metadata":{}},{"cell_type":"code","source":"# List of hashtags to scrape images from\nhashtags = ['nature', 'food', 'fashion', 'travel']\n\n# Iterate over each hashtag\nfor hashtag in hashtags:\n    # Go to the Instagram hashtag page\n    driver.get(f'https://www.instagram.com/explore/tags/{hashtag}/')\n    \n    # Optional zoom out to see more images in the browser\n    driver.execute_script(f\"document.body.style.zoom='{0.40}'\")\n    \n    time.sleep(5)  # Wait for the page to load","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **trick number 2**\n\n\n- when looping on images the screen must be scrolled to load more images\n- main_download_dir is the place where images will be saved\n","metadata":{}},{"cell_type":"code","source":"scroll_amount = 500  # Scroll by 500 pixels each time\nmax_scrolls = 10     # Set the maximum number of scrolls before stopping\nscroll_count = 0     # Counter for the number of scrolls\n    \nmain_download_dir = r'*:/ where/you/want/to/save'  # Set the directory where images will be saved\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **trick number 3**\n\n- used to scroll from the first of the page until \"scroll_amount\"\n- Retrieve all image URLs on the current page is an important step\n\n","metadata":{}},{"cell_type":"code","source":"    while scroll_count < max_scrolls:\n        # Scroll down by a small amount\n        driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n    \n        # Wait for the page to load new images\n        time.sleep(3)\n\n        # Target all images on the page\n        img_tags = driver.find_elements(By.TAG_NAME, 'img')\n    \n        # Extract 'src' attribute (URL) of each image and add it to the set of unique URLs\n        # Retrieve all image URLs on the current page\n        for img_tag in img_tags:\n            img_url = img_tag.get_attribute('src')\n            if img_url not in unique_image_urls:\n                unique_image_urls.add(img_url)  # Add only new unique URLs\n        \n        # Increment the scroll count\n        scroll_count += 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **trick number 4**\n\n- Create a folder named as the scrapped class\n- looping and downloading the images\n","metadata":{}},{"cell_type":"code","source":" # Create a folder for the hashtag within the main download directory\n    download_dir = os.path.join(main_download_dir, hashtag)\n    os.makedirs(download_dir, exist_ok=True)\n\n    # Loop through each image URL and download the image\n    for idx, src in enumerate(unique_image_urls):\n        try:\n            file_ext = 'jpg'  # Default to 'jpg' for image extension\n            file_path = os.path.join(download_dir, f'img_{idx}.{file_ext}')\n            # Download the image\n            urllib.request.urlretrieve(src, file_path)\n        except Exception as e:\n            print(f\"Failed to retrieve image: {e}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Finaly Close the WebDriver**","metadata":{}},{"cell_type":"code","source":"# Close the WebDriver session\ndriver.quit()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **HERE YOU CAN RUN THE WHOLE CODE**","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport time\nimport urllib.request\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.keys import Keys\n\n\n\n\n\n# Set the path to your ChromeDriver\ndriver_path = r'E:\\driver\\chromedriver-win64\\chromedriver.exe'  # Replace with the correct path to your ChromeDriver\n\n# Set up Chrome options (Optional: Headless mode if you want to run without opening a browser window)\nchrome_options = Options()\n\n# Initialize WebDriver\nservice = Service(executable_path=driver_path)\ndriver = webdriver.Chrome(service=service, options=chrome_options)\n\n# Instagram login page\ndriver.get('https://www.instagram.com/accounts/login/')\ntime.sleep(2)  # Wait for the login page to load\n\n# Find the username and password fields and enter credentials\n# *** You need to replace the username and password  ***\nusername_field = driver.find_element(By.NAME, 'username')\npassword_field = driver.find_element(By.NAME, 'password')\nusername_field.send_keys('******')  # Replace with your credentials\npassword_field.send_keys('******')  # Replace with your credentials\npassword_field.send_keys(Keys.RETURN)  # Press Enter to log in\n\ntime.sleep(5)  # Wait for login to complete\n\n\n\n\n\n\n\n\n# List of hashtags to scrape images from\n# you can change this classes by what you need\nhashtags = ['nature', 'food', 'fashion', 'travel']\n\n# Iterate over each hashtag\nfor hashtag in hashtags:\n    # Go to the Instagram hashtag page\n    driver.get(f'https://www.instagram.com/explore/tags/{hashtag}/')\n    \n    # Optional zoom out to see more images in the browser\n    driver.execute_script(f\"document.body.style.zoom='{0.40}'\")\n    \n    time.sleep(5)  # Wait for the page to load\n\n    # Set to hold unique image URLs\n    unique_image_urls = set()\n\n    scroll_amount = 500  # Scroll by 500 pixels each time\n    max_scrolls = 10     # Set the maximum number of scrolls before stopping\n    scroll_count = 0     # Counter for the number of scrolls\n    \n    main_download_dir = r'*:/ where/you/want/to/save'  # Set the directory where images will be saved\n    \n   \n\n    while scroll_count < max_scrolls:\n        # Scroll down by a small amount\n        driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n    \n        # Wait for the page to load new images\n        time.sleep(3)\n\n        # Target all images on the page\n        img_tags = driver.find_elements(By.TAG_NAME, 'img')\n    \n        # Extract 'src' attribute (URL) of each image and add it to the set of unique URLs\n        for img_tag in img_tags:\n            img_url = img_tag.get_attribute('src')\n            if img_url not in unique_image_urls:\n                unique_image_urls.add(img_url)  # Add only new unique URLs\n        \n        # Increment the scroll count\n        scroll_count += 1\n\n        \n        \n        \n    # Create a folder for the hashtag within the main download directory\n    download_dir = os.path.join(main_download_dir, hashtag)\n    os.makedirs(download_dir, exist_ok=True)\n\n    # Loop through each image URL and download the image\n    for idx, src in enumerate(unique_image_urls):\n        try:\n            file_ext = 'jpg'  # Default to 'jpg' for image extension\n            file_path = os.path.join(download_dir, f'img_{idx}.{file_ext}')\n            # Download the image\n            urllib.request.urlretrieve(src, file_path)\n        except Exception as e:\n            print(f\"Failed to retrieve image: {e}\")\n\n            \n            \n            \n            \n            \n# Close the WebDriver session\ndriver.quit()\n","metadata":{},"execution_count":null,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d772fc3b",
   "metadata": {},
   "source": [
    "# **Best Web Scraping for Instagram with Selenium**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac8e1c",
   "metadata": {},
   "source": [
    "# Install selenium Libraries\n",
    "\n",
    "- Selenium libraries allows you to interact with dynamic content and scroll through the page to load more posts.\n",
    "- there is a lot of more other options that can help you too \n",
    "      \n",
    " ### **First web scraping techniques :**\n",
    "     -BeautifulSoup\n",
    "     -Selenium\n",
    "                                                             \n",
    " ### **Second third-party libraries like :**\n",
    "     -Instaloader                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b048d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee49cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade selenium # IF NEADED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73589e40",
   "metadata": {},
   "source": [
    "# **\" DON'T \"**  \n",
    "\n",
    "# **RUN** **THE**  **CELLS**\n",
    "\n",
    "# **RUN**  **THE**  **WHOLE**  **CODE**\n",
    "\n",
    "# **BELOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b17a21b",
   "metadata": {},
   "source": [
    "## **Download Chrome Driver**\n",
    "\n",
    "important\n",
    "\n",
    "**Now we need to download latest stable release of ChromeDriver from:**\n",
    "\n",
    "https://github.com/GoogleChromeLabs/chrome-for-testing/blob/main/data/latest-versions-per-milestone-with-downloads.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9258f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your ChromeDriver (In Kaggle, you'll need to install ChromeDriver first)\n",
    "driver_path = r'E:\\driver\\chromedriver-win64\\chromedriver.exe'  # Replace with the correct path for Kaggle or download it in the notebook\n",
    "\n",
    "# Set up Chrome options (Headless mode is useful when running in Kaggle, as there is no GUI)\n",
    "chrome_options = Options()\n",
    "\n",
    "# Initialize WebDriver\n",
    "service = Service(executable_path=driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813f69a",
   "metadata": {},
   "source": [
    "## **login to the page by writing  \"username\" & \"password\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d714bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instagram login page\n",
    "driver.get('https://www.instagram.com/accounts/login/')\n",
    "time.sleep(2)  # Wait for the login page to load\n",
    "\n",
    "# Find the username and password fields and enter credentials\n",
    "# *** You need to replace the username and password  ***\n",
    "username_field = driver.find_element(By.NAME, 'username')\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "username_field.send_keys('4ooha2')  # Replace with your credentials\n",
    "password_field.send_keys('alyhassan')  # Replace with your credentials\n",
    "password_field.send_keys(Keys.RETURN)  # Press Enter to log in\n",
    "\n",
    "time.sleep(5)  # Wait for login to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e49f4d",
   "metadata": {},
   "source": [
    "## **trick number 1**\n",
    "\n",
    "- now you have to targit your goal and \"classes\" \n",
    "- and ('https://www.instagram.com/explore/tags/{hashtag}/') is our goal and classes are hashtags\n",
    "- browser is -40 zoom out to see more images in the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ef969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of hashtags to scrape images from\n",
    "hashtags = ['nature', 'food', 'fashion', 'travel']\n",
    "\n",
    "# Iterate over each hashtag\n",
    "for hashtag in hashtags:\n",
    "    # Go to the Instagram hashtag page\n",
    "    driver.get(f'https://www.instagram.com/explore/tags/{hashtag}/')\n",
    "    \n",
    "    # Optional zoom out to see more images in the browser\n",
    "    driver.execute_script(f\"document.body.style.zoom='{0.40}'\")\n",
    "    \n",
    "    time.sleep(5)  # Wait for the page to load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6169058",
   "metadata": {},
   "source": [
    "## **trick number 2**\n",
    "\n",
    "\n",
    "- when looping on images the screen must be scrolled to load more images\n",
    "- main_download_dir is the place where images will be saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee69d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll_amount = 500  # Scroll by 500 pixels each time\n",
    "max_scrolls = 10     # Set the maximum number of scrolls before stopping\n",
    "scroll_count = 0     # Counter for the number of scrolls\n",
    "    \n",
    "main_download_dir = r'E:\\fofo'  # Set the directory where images will be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2e752",
   "metadata": {},
   "source": [
    "## **trick number 3**\n",
    "\n",
    "- used to scroll from the first of the page until \"scroll_amount\"\n",
    "- Retrieve all image URLs on the current page is an important step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4311ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "    while scroll_count < max_scrolls:\n",
    "        # Scroll down by a small amount\n",
    "        driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
    "    \n",
    "        # Wait for the page to load new images\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Target all images on the page\n",
    "        img_tags = driver.find_elements(By.TAG_NAME, 'img')\n",
    "    \n",
    "        # Extract 'src' attribute (URL) of each image and add it to the set of unique URLs\n",
    "        # Retrieve all image URLs on the current page\n",
    "        for img_tag in img_tags:\n",
    "            img_url = img_tag.get_attribute('src')\n",
    "            if img_url not in unique_image_urls:\n",
    "                unique_image_urls.add(img_url)  # Add only new unique URLs\n",
    "        \n",
    "        # Increment the scroll count\n",
    "        scroll_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b0b9e",
   "metadata": {},
   "source": [
    "## **trick number 4**\n",
    "\n",
    "- Create a folder named as the scrapped class\n",
    "- looping and downloading the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a folder for the hashtag within the main download directory\n",
    "    download_dir = os.path.join(main_download_dir, hashtag)\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through each image URL and download the image\n",
    "    for idx, src in enumerate(unique_image_urls):\n",
    "        try:\n",
    "            file_ext = 'jpg'  # Default to 'jpg' for image extension\n",
    "            file_path = os.path.join(download_dir, f'img_{idx}.{file_ext}')\n",
    "            # Download the image\n",
    "            urllib.request.urlretrieve(src, file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to retrieve image: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae95c38",
   "metadata": {},
   "source": [
    "## **Finaly Close the WebDriver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the WebDriver session\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7226242",
   "metadata": {},
   "source": [
    "# **HERE YOU CAN RUN THE WHOLE CODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set the path to your ChromeDriver\n",
    "driver_path = r'E:\\driver\\chromedriver-win64\\chromedriver.exe'  # Replace with the correct path to your ChromeDriver\n",
    "\n",
    "# Set up Chrome options (Optional: Headless mode if you want to run without opening a browser window)\n",
    "chrome_options = Options()\n",
    "\n",
    "# Initialize WebDriver\n",
    "service = Service(executable_path=driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Instagram login page\n",
    "driver.get('https://www.instagram.com/accounts/login/')\n",
    "time.sleep(2)  # Wait for the login page to load\n",
    "\n",
    "# Find the username and password fields and enter credentials\n",
    "# *** You need to replace the username and password  ***\n",
    "username_field = driver.find_element(By.NAME, 'username')\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "username_field.send_keys('4ooha2')  # Replace with your credentials\n",
    "password_field.send_keys('alyhassan')  # Replace with your credentials\n",
    "password_field.send_keys(Keys.RETURN)  # Press Enter to log in\n",
    "\n",
    "time.sleep(5)  # Wait for login to complete\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# List of hashtags to scrape images from\n",
    "hashtags = ['nature', 'food', 'fashion', 'travel']\n",
    "\n",
    "# Iterate over each hashtag\n",
    "for hashtag in hashtags:\n",
    "    # Go to the Instagram hashtag page\n",
    "    driver.get(f'https://www.instagram.com/explore/tags/{hashtag}/')\n",
    "    \n",
    "    # Optional zoom out to see more images in the browser\n",
    "    driver.execute_script(f\"document.body.style.zoom='{0.40}'\")\n",
    "    \n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "    # Set to hold unique image URLs\n",
    "    unique_image_urls = set()\n",
    "\n",
    "    scroll_amount = 500  # Scroll by 500 pixels each time\n",
    "    max_scrolls = 10     # Set the maximum number of scrolls before stopping\n",
    "    scroll_count = 0     # Counter for the number of scrolls\n",
    "    main_download_dir = r'E:\\fofo'  # Set the directory where images will be saved\n",
    "    \n",
    "    # Make sure the main download directory exists\n",
    "    os.makedirs(main_download_dir, exist_ok=True)\n",
    "\n",
    "    while scroll_count < max_scrolls:\n",
    "        # Scroll down by a small amount\n",
    "        driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
    "    \n",
    "        # Wait for the page to load new images\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Target all images on the page\n",
    "        img_tags = driver.find_elements(By.TAG_NAME, 'img')\n",
    "    \n",
    "        # Extract 'src' attribute (URL) of each image and add it to the set of unique URLs\n",
    "        for img_tag in img_tags:\n",
    "            img_url = img_tag.get_attribute('src')\n",
    "            if img_url not in unique_image_urls:\n",
    "                unique_image_urls.add(img_url)  # Add only new unique URLs\n",
    "        \n",
    "        # Increment the scroll count\n",
    "        scroll_count += 1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Create a folder for the hashtag within the main download directory\n",
    "    download_dir = os.path.join(main_download_dir, hashtag)\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through each image URL and download the image\n",
    "    for idx, src in enumerate(unique_image_urls):\n",
    "        try:\n",
    "            file_ext = 'jpg'  # Default to 'jpg' for image extension\n",
    "            file_path = os.path.join(download_dir, f'img_{idx}.{file_ext}')\n",
    "            # Download the image\n",
    "            urllib.request.urlretrieve(src, file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to retrieve image: {e}\")\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# Close the WebDriver session\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
